
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Required packages
```{r}

library(ncdf4)
library(tidyverse)
library(chron)
library(reshape2)
library(lubridate)
#you may need in increase your memory limit to read in the large netCDF file ; R wouldn't accept a vector of this size otherwise

memory.limit()

memory.limit(22000)

baseDir <- "C:/Users/samsi/Dropbox/"
```

#General outline / workflow
```{r}

## Read in surface temp netcdf file from https://www.sciencebase.gov/catalog/item/60341c3ed34eb12031172aa6

## Pull out variables and attributes from the netcdf file to derive a matrix of siteID, date, and temp values

## Pull out nhdid from training file prior to joining training to surf_temp by nhdid

## Join the two together by date and nhdid

```

#Read in surface temp file and derive a matrix of siteID, date, and temp values
```{r}

nc_dat <- nc_open(paste0(baseDir, "01_predicted_temp_N24-53_W98-126.nc"))

print(paste("The file has",nc_dat$nvars,"variables,",nc_dat$ndims,"dimensions and",nc_dat$natts,"NetCDF attributes"))

#The variables are: alt (approx elevation), lat, lon, and surftemp

#retrieve a matrix of the surf temp data 

surf_temp <- ncvar_get(nc_dat, attributes(nc_dat$var)$names[4])

dim(surf_temp)

#dimensions are 14976 x 62560

attributes(nc_dat$dim)

#attributes are site_id, site_id_char, and time; I'm going to want the site_id and the time to add to the surf_temp matrix

nc_siteid <- ncvar_get( nc_dat, attributes(nc_dat$dim)$names[1])

nc_time <- ncvar_get( nc_dat, attributes(nc_dat$dim)$names[3])

print(paste(dim(nc_time), "times and", dim(nc_siteid), "site_ids"))

#dimensions for surf_temp and nc_time and nc_siteid match

dimnames(surf_temp) <- list(time = nc_time, siteid = nc_siteid)

surf_temp <- t(surf_temp) #transpose the matrix

```

#Pull out nhdid's from training file that we'll use to filter matrix
```{r}

#First pull out nhdids from surf_temp matrix

site_ids <- as.data.frame(nc_siteid)

#These ids have a prefix of "nhdhr_" that we will have to remove for the timebeing 

site_ids <- site_ids %>%
  transform(nc_siteid = str_replace(nc_siteid, "nhdhr_", ""))

# Now dig up nhdids from training/aquasat file
lake_ids <- read.csv("C:/Users/samsi/Dropbox/limnosat_pred_data.csv") %>%
  select(lagoslakeid)

lake_ids <- lake_ids %>%
  distinct(lagoslakeid)

#get nhdid from orig lagos file ; should have included this in original merging of datasets
lagos_ids <- read.csv(paste0(baseDir,"/CL_LAGOSUS_exports/LAGOSUS_LOCUS/LOCUS_v1.0/lake_information.csv")) %>%
  filter(lagoslakeid %in% lake_ids$lagoslakeid) %>%
  select(lake_nhdid)

site_ids <- site_ids %>%
  filter(nc_siteid %in% lagos_ids$lake_nhdid)

#not a prefect matchup; missing ~ 20 obs, could be because some lakes are too small in training set and aren't included in this temp data ? 

#re_apply the nhdhr prefix
site_ids$nc_siteid = paste0('nhdhr_', site_ids$nc_siteid)

#Have to create a character string of site_ids included in site_ids (this might be weird and convoluted but it worked for me...)

site_ids <- site_ids %>%
  mutate(blank = 0 )

site_ids <- pivot_wider(site_ids, names_from = nc_siteid, values_from = blank)

site_ids <- as.character(colnames(site_ids))

#subset surf_temp dataset to include the lakes that are included in the training/aquasat file

surf_temp <- surf_temp[site_ids , ]

df.surf_temp <- as.data.frame(surf_temp)

rm(surf_temp) # remove matrix

df.surf_temp <- tibble::rownames_to_column(df.surf_temp, "siteID")

```

#Convert time (days from x) to meaningful date field
```{r}
time <- ncvar_get(nc_dat,"time")

tunits <- ncatt_get(nc_dat,"time","units")

tustr <- strsplit(tunits$value, " ")
tdstr <- strsplit(unlist(tustr)[3], "-")
tmonth <- as.integer(unlist(tdstr)[2])
tday <- as.integer(unlist(tdstr)[3])
tyear <- as.integer(unlist(tdstr)[1])

nc_time <- as.data.frame(nc_time)

days <- as_data_frame(chron(time,origin=c(tmonth, tday, tyear))) %>%
  mutate(number = nc_time$nc_time)

days$number <- as.factor(days$number)

df.surf_temp <- melt(df.surf_temp, id.vars = 1)

df.surf_temp <- df.surf_temp %>%
  rename(number = "variable", 
         temp = "value")

df.surf_temp <- left_join(df.surf_temp, days, by = "number")


head(df.surf_temp) #check

nc_close(nc_dat)

```

#set up to merge to training set 
```{r}
df.surf_temp <- df.surf_temp %>%
  rename(date = "value")

class(df.surf_temp$date)

df.surf_temp$date <- as_date(df.surf_temp$date)

df.surf_temp$date <- ymd(df.surf_temp$date)

```

#filtering for start date 7 - day, 14 - day, and end date 
```{r}
df.surf_temp <- df.surf_temp %>%
  mutate(start_date_7 = date - 7,
         start_date_14 = date - 14,
         end_date = date)
```


#remove nhd prefix from temp df; add nhdid to training from lagos files; merge the two together by nhdid , date

```{r}

df.surf_temp <- df.surf_temp %>%
  transform(siteID = str_replace(siteID, "nhdhr_", ""))

training <- read.csv("C:/Users/samsi/Dropbox/training.csv")

lagos_ids <- read.csv(paste0(baseDir,"/CL_LAGOSUS_exports/LAGOSUS_LOCUS/LOCUS_v1.0/lake_information.csv")) %>%
  filter(lagoslakeid %in% training$lagoslakeid) %>%
  select(lagoslakeid, lake_nhdid) %>%
  rename(siteID = lake_nhdid)

test <- left_join(df.surf_temp, lagos_ids, by = 'siteID')



test2 <- test %>%
  group_by(lagoslakeid, end_date) %>%
  filter(date >= start_date_7 & date <= date) %>%
  summarise(mean7day = mean(temp))




temp_7 <- temp_7 %>%
  distinct(lagoslakeid, date, end_date, temp)

temp_7 <- temp_7 %>%
  group_by(lagoslakeid, end_date) %>%


temp_7 <- temp_7 %>%
  rename(date = "end_date")

temp_14 <- temp_14 %>%
  rename(date = "end_date")

#match dates to training dates for merging
training <- read.csv("C:/Users/samsi/Dropbox/limnosat_pred_data.csv")

training$date <- as_date(training$date)

training <- left_join(training, temp_14, by = c('lagoslakeid', 'date'))

training <- left_join(training, temp_7, by = c('lagoslakeid', 'date'))

temp_day_of <- test %>%
  select(lagoslakeid, date, temp)

training <- left_join(training, temp_day_of, by = c('lagoslakeid', 'date'))

training <- write.csv(training, "C:/Users/samsi/Dropbox/training.csv")
```


#Do same process but for wind speed 
```{r}
#remove vars from work environment
rm(days, df.surf_temp, lagos_ids, lake_ids, nc_dat, nc_time, tdstr, temp_14, temp_7, temp_7day, temp_day_of, test, tunits, tustr)

nc_dat <- nc_open(paste0(baseDir, "01_weather_N24-53_W98-126.nc"))

print(paste("The file has",nc_dat$nvars,"variables,",nc_dat$ndims,"dimensions and",nc_dat$natts,"NetCDF attributes"))

nc_dat$var

#weather id attaches weather vars (wind speed) to lakes 

#retrieve a matrix of the wind data (7 = 10-m above ground meridional wind speed (m/s) ; 6 = 10-m above ground zonal wind speed (m/s))

wind_speed <- ncvar_get(nc_dat, attributes(nc_dat$var)$names[7])

dim(wind_speed)

#dimensions are 14976 x 62560

attributes(nc_dat$dim)

#attributes are weather_id, time, weather_id_char; I'm going to want the weather id and time to add to the surf_temp matrix

nc_siteid <- ncvar_get( nc_dat, attributes(nc_dat$dim)$names[1])

nc_time <- ncvar_get( nc_dat, attributes(nc_dat$dim)$names[2])

print(paste(dim(nc_time), "times and", dim(nc_siteid), "site_ids"))

#dimensions for surf_temp and nc_time and nc_siteid match

dimnames(wind_speed) <- list(time = nc_time, siteid = nc_siteid)

wind_speed <- t(wind_speed) #transpose the matrix

```

#Pull out nhdid's from training file that we'll use to filter matrix
```{r}

#First pull out nhdids from surf_temp matrix

site_ids <- as.data.frame(nc_siteid)

#Add in lake metadata that links lake ids to weather ids 

metadata <- read.csv("C:/Users/samsi/Downloads/lake_metadata.csv")

training <- read.csv("C:/Users/samsi/Dropbox/training.csv")

lagos_ids <- read.csv(paste0(baseDir,"/CL_LAGOSUS_exports/LAGOSUS_LOCUS/LOCUS_v1.0/lake_information.csv")) %>%
  filter(lagoslakeid %in% training$lagoslakeid) %>%
  select(lake_nhdid, lagoslakeid)

metadata <- metadata %>%
  transform(site_id = str_replace(site_id, "nhdhr_", ""))

site_ids <- metadata %>%
  select(site_id, weather_id) %>%
  filter(site_id %in% lagos_ids$lake_nhdid)

site_ids <- site_ids %>%
  select(weather_id)

site_ids <- site_ids %>%
  mutate(blank = 0 )

site_ids <- pivot_wider(site_ids, names_from = weather_id, values_from = blank)

site_ids <- as.character(colnames(site_ids))

#subset surf_temp dataset to include the lakes that are included in the training/aquasat file

wind_speed <- wind_speed[site_ids , ]

wind_speed <- as.data.frame(wind_speed)

wind_speed <- tibble::rownames_to_column(wind_speed, "weatherID")

```

#Convert time (days from x) to meaningful date field
```{r}
time <- ncvar_get(nc_dat,"time")

tunits <- ncatt_get(nc_dat,"time","units")

tustr <- strsplit(tunits$value, " ")
tdstr <- strsplit(unlist(tustr)[3], "-")
tmonth <- as.integer(unlist(tdstr)[2])
tday <- as.integer(unlist(tdstr)[3])
tyear <- as.integer(unlist(tdstr)[1])

nc_time <- as.data.frame(nc_time)

days <- as_data_frame(chron(time,origin=c(tmonth, tday, tyear))) %>%
  mutate(number = nc_time$nc_time)

days$number <- as.factor(days$number)

wind_speed <- melt(wind_speed, id.vars = 1)

wind_speed <- wind_speed %>%
  rename(number = "variable", 
         wind = "value")

wind_speed <- left_join(wind_speed, days, by = "number")


head(wind_speed) #check

nc_close(nc_dat)

id <- metadata %>%
  select(weather_id, site_id)

lagos_ids <- lagos_ids %>%
  rename(site_id = lake_nhdid)

id <- left_join(id, lagos_ids, by = 'site_id')

id <- id %>%
  drop_na()

id <- id %>%
  rename(weatherID = 'weather_id')

wind_speed <- left_join(wind_speed, id , by = 'weatherID')

wind_speed <- wind_speed %>%
  rename(date = 'value')

wind_speed$date <- as_date(wind_speed$date)

training$date <- as_date(training$date)

training <- left_join(training, wind_speed, by = c('lagoslakeid', 'date'))

training <- write.csv(training, "C:/Users/samsi/Dropbox/training.csv")

```



